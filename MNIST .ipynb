{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import the packages \n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0)\n",
    "plt.rcParams['image.cmap'] = 'Greys'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#Read the mnist data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n",
      "(55000, 10)\n"
     ]
    }
   ],
   "source": [
    "#The data consists of 55000 training images and labels\n",
    "#The data consists of 10000 testing images and labels\n",
    "print(mnist.train.images.shape)\n",
    "print(mnist.train.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(mnist.test.images.shape)\n",
    "print(mnist.test.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x264605234e0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2645f86dac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_image = mnist.train.images[1]\n",
    "example_image_reshaped = example_image.reshape((28, 28)) # Can't render a line of 784 numbers\n",
    "example_label = mnist.train.labels[1]\n",
    "\n",
    "print(example_label)\n",
    "plt.imshow(example_image_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create placeholder for input image and respective labels\n",
    "#The images are greyscale and are 28x28 pixels in size, which is stored as an array of 784 length\n",
    "#The labels are an array of size 10(No. of classes)\n",
    "x = tf.placeholder(tf.float32, [None,784])\n",
    "y_ = tf.placeholder(tf.float32, [None,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create variables for Weights and biases and apply ReLu Activation function \n",
    "W1 = tf.Variable(tf.truncated_normal(shape=[784,100], stddev=0.1))\n",
    "b1 = tf.Variable(tf.constant(0.1, shape=[100]))\n",
    "h1 = tf.nn.relu(tf.matmul(x,W1)+b1)\n",
    "#Create variables for Weights and biases and apply Softmax function to get the prediction\n",
    "W2 = tf.Variable(tf.truncated_normal(shape=[100,10],stddev=0.1))\n",
    "b2 = tf.Variable(tf.constant(0.1, shape=[10]))\n",
    "y = tf.nn.softmax(tf.matmul(h1,W2)+b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the cross entropy loss\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y),reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train the model\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Run the session\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training\n",
    "for i in range(1000):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9617\n"
     ]
    }
   ],
   "source": [
    "#Check the accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
